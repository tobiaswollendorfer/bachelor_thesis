{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c344a8f2-988d-4bf3-a630-badd7f7b8b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c1c3bec-1377-4433-8ad0-05e7bd8a4077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10286 CSV files to process\n",
      "Output folder: comments/preprocessed_with_vader\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "input_folder = \"comments/preprocessed_comments\"\n",
    "output_folder = \"comments/preprocessed_with_vader\"  # New folder for VADER results\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize VADER analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Get all CSV files\n",
    "all_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "total_files = len(all_files)\n",
    "\n",
    "print(f\"Found {total_files} CSV files to process\")\n",
    "print(f\"Output folder: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcb60d52-6231-47fe-97cb-cb33def846e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files processed: 1000/10286, expected finishing time: 2025-08-14 14:18:15.974055\n",
      "files processed: 2000/10286, expected finishing time: 2025-08-14 14:18:19.516964\n",
      "files processed: 3000/10286, expected finishing time: 2025-08-14 14:18:21.548763\n",
      "files processed: 4000/10286, expected finishing time: 2025-08-14 14:18:21.562048\n",
      "files processed: 5000/10286, expected finishing time: 2025-08-14 14:18:21.116259\n",
      "files processed: 6000/10286, expected finishing time: 2025-08-14 14:18:27.510720\n",
      "files processed: 7000/10286, expected finishing time: 2025-08-14 14:18:28.186750\n",
      "files processed: 8000/10286, expected finishing time: 2025-08-14 14:18:28.268126\n",
      "files processed: 9000/10286, expected finishing time: 2025-08-14 14:18:29.136782\n",
      "files processed: 10000/10286, expected finishing time: 2025-08-14 14:18:29.519997\n",
      "files processed: 10286/10286, expected finishing time: 2025-08-14 14:18:29.539942\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "no_comment_column = []\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "for idx, filename in enumerate(all_files, 1):\n",
    "    # Create output filename with _vader suffix\n",
    "    base_name = filename.replace('.csv', '')\n",
    "    output_filename = f\"{base_name}_vader.csv\"\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        if 'preprocessed_comment' not in df.columns:\n",
    "            print(f\"Warning: No 'preprocessed_comment' column found in {filename}. Available columns: {list(df.columns)}\")\n",
    "            no_comment_column.append(filename)\n",
    "            continue\n",
    "\n",
    "        vader_scores = df['preprocessed_comment'].apply(\n",
    "            lambda comment: analyzer.polarity_scores(str(comment)) \n",
    "            if pd.notna(comment) and str(comment).strip() != \"\" \n",
    "            else {'compound': 0, 'pos': 0, 'neu': 0, 'neg': 0}\n",
    "        )\n",
    "\n",
    "        vader_scores_df = pd.DataFrame(list(vader_scores))\n",
    "\n",
    "        vader_scores_df.columns = ['vader_' + col for col in vader_scores_df.columns]\n",
    "\n",
    "        for col in vader_scores_df.columns:\n",
    "            df[col] = vader_scores_df[col]\n",
    "        \n",
    "        base_name = filename.replace('.csv', '')\n",
    "        output_filename = f\"{base_name}_vader.csv\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        \n",
    "        processed_count += 1\n",
    "        \n",
    "        if idx % 1000 == 0 or idx == total_files:\n",
    "            elapsed = time.time() - start_time\n",
    "            processed_so_far = processed_count\n",
    "            if processed_so_far > 0:\n",
    "                avg_per_file = elapsed / processed_so_far\n",
    "                remaining_files = total_files - idx\n",
    "                est_remaining = avg_per_file * remaining_files\n",
    "                finish_time = datetime.now() + timedelta(seconds=est_remaining)\n",
    "                print(f\"files processed: {processed_so_far}/{len(all_files)}, expected finishing time: {finish_time}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        no_comment_column.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175aeb2-0b17-474a-a28b-e99245854adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb3049-63d0-4eae-8d57-986f4983e7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bachelor_thesis)",
   "language": "python",
   "name": "bachelor_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
