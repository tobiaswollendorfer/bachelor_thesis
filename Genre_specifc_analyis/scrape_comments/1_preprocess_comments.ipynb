{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fba6782d-6de8-43fa-a85f-836b7ef87245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from langdetect import detect, DetectorFactory, LangDetectException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d48ae451-c3c6-4bf4-9bb8-b81f55486cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \\n, \\t & multiple spaces\n",
    "def preprocessing_remove_newlines_tabs_and_spaces(text: str) -> str:\n",
    "    text_cleaned = re.sub(r'[\\n\\t]+', ' ', text)\n",
    "    text_final = re.sub(r'\\s+', ' ', text_cleaned).strip()\n",
    "    \n",
    "    return text_final\n",
    "    #all lower case\n",
    "def preprocessing_lowercase(text: str) -> str:\n",
    "     return text.lower()\n",
    "    \n",
    "def preprocessing_remove_punctuation(text: str) -> str:\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def preprocess_combined(text: str) -> str:\n",
    "    text_no_punctuation = preprocessing_remove_punctuation(text)\n",
    "    text_cleaned = preprocessing_remove_newlines_tabs_and_spaces(text_no_punctuation)\n",
    "    preprocessed = preprocessing_lowercase(text_cleaned) \n",
    "    return preprocessed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40eecab4-3e3b-4f3c-8457-c1c9a7dbb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectorFactory.seed = 0 \n",
    "\n",
    "def safe_detect_lang(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"unknown\"\n",
    "    t = text.strip()\n",
    "    if len(t) < 2:\n",
    "        return \"unknown\"\n",
    "    try:\n",
    "        return detect(t)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c41c3df-66aa-48cd-bdf7-455e562b0c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         this is on of her best songsðŸŒŠ\n",
      "1     ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰...\n",
      "2                              nice ballad by lisa ajax\n",
      "3                                        din rÃ¶st wowâ¤ï¸\n",
      "4                  vÃ¤rldens bÃ¤sta mÃ¤nniska Ã¤lskar digâ¤ï¸\n",
      "                            ...                        \n",
      "95                                               winner\n",
      "96                                     instrumental pls\n",
      "97    12 points from belgium i think it is mind blow...\n",
      "98               live is even better we love you lisa â¤\n",
      "99    best song in melfest this year rooting for you...\n",
      "Name: preprocessed_comment, Length: 100, dtype: object\n",
      "Processed 1000/10286 files in 217.45s.\n",
      "Estimated total: 2236.71s. Remaining: 2019.25s.\n",
      "Processed 2000/10286 files in 453.45s.\n",
      "Estimated total: 2332.10s. Remaining: 1878.65s.\n",
      "Processed 3000/10286 files in 675.98s.\n",
      "Estimated total: 2317.70s. Remaining: 1641.72s.\n",
      "0                                                     â¤\n",
      "1     hell yeah bring me my loveley old time and mus...\n",
      "2                                                     â¤\n",
      "3                                         2024 hatelove\n",
      "4                                                  â¤ï¸â€ðŸ©¹\n",
      "                            ...                        \n",
      "72      thanks a lot i was searching the lyrics so long\n",
      "73                            nice track got to agree 5\n",
      "74                 this is my favorite song from them o\n",
      "75           there best songto hot steeve from montreal\n",
      "76                                             thx 4 up\n",
      "Name: preprocessed_comment, Length: 77, dtype: object\n",
      "Processed 4000/10286 files in 903.43s.\n",
      "Estimated total: 2323.16s. Remaining: 1419.74s.\n",
      "Processed 5000/10286 files in 1144.69s.\n",
      "Estimated total: 2354.86s. Remaining: 1210.17s.\n",
      "Processed 6000/10286 files in 1410.88s.\n",
      "Estimated total: 2418.71s. Remaining: 1007.84s.\n",
      "0       day 1477 of listening to the beautiful theme ðŸ˜ŒðŸŽ§\n",
      "1     day 1476 of listening to this beautiful theme ...\n",
      "2                             038 when my phone is at 1\n",
      "3       day 1475 of listening to this beautiful themeðŸ˜ŒðŸŽ§\n",
      "4      day 1474 of listening to this beautiful theme ðŸ˜ŒðŸŽ§\n",
      "                            ...                        \n",
      "95     day 1398 of listening to this beautiful theme ðŸ˜ŒðŸŽ§\n",
      "96      day 1397 of listening to this beautiful themeðŸ˜ŒðŸŽ§\n",
      "97     day 1396 of listening to this beautiful theme ðŸ˜ŒðŸŽ§\n",
      "98     day 1395 of listening to this beautiful theme ðŸ˜ŒðŸŽ§\n",
      "99     day 1394 of listening to this beautiful theme ðŸ˜ŒðŸŽ§\n",
      "Name: preprocessed_comment, Length: 100, dtype: object\n",
      "Processed 7000/10286 files in 1643.67s.\n",
      "Estimated total: 2415.25s. Remaining: 771.58s.\n",
      "Processed 8000/10286 files in 1880.68s.\n",
      "Estimated total: 2418.08s. Remaining: 537.40s.\n",
      "Processed 9000/10286 files in 2125.45s.\n",
      "Estimated total: 2429.15s. Remaining: 303.70s.\n",
      "0     after 8 years this song and the movie is still...\n",
      "1                                  still here in 2025 â¤\n",
      "2     ive been searching for this song for a long ti...\n",
      "3     cute video until you realize thats taylor from...\n",
      "4                                     volta cantar ðŸ˜¢ðŸ˜¢ðŸ˜¢ðŸ˜¢\n",
      "                            ...                        \n",
      "95    excellent song video my favourite video best s...\n",
      "96    my heart and soul usa usa usa usa usa usa usa ...\n",
      "97    i love you my motherland usa usa usa usa usa u...\n",
      "98    i am really american boy so i love you this vi...\n",
      "99    best song video my favourite video i love you ...\n",
      "Name: preprocessed_comment, Length: 100, dtype: object\n",
      "Processed 10000/10286 files in 2367.73s.\n",
      "Estimated total: 2435.44s. Remaining: 67.72s.\n",
      "\n",
      "Processing Summary:\n",
      "-------------------\n",
      "CSV files found: 10286\n",
      "Files successfully processed: 10286\n",
      "Files with missing 'textOriginal' column: 0\n",
      "File opening errors: 0\n",
      "\n",
      "Language distribution across all comments:\n",
      "-----------------------------------------\n",
      "en = 356973\n",
      "pt = 46917\n",
      "unknown = 38471\n",
      "es = 36376\n",
      "de = 14069\n",
      "fr = 12711\n",
      "it = 11183\n",
      "tl = 8492\n",
      "pl = 8342\n",
      "ja = 8255\n",
      "so = 7727\n",
      "ru = 6264\n",
      "af = 6181\n",
      "ca = 5726\n",
      "ro = 5608\n",
      "id = 5191\n",
      "nl = 5158\n",
      "no = 4803\n",
      "da = 4281\n",
      "cy = 4117\n",
      "et = 3845\n",
      "ko = 3735\n",
      "tr = 3538\n",
      "fi = 3255\n",
      "sw = 3108\n",
      "sv = 3055\n",
      "sl = 2542\n",
      "vi = 2332\n",
      "hu = 2093\n",
      "hr = 1911\n",
      "sk = 1324\n",
      "lt = 1250\n",
      "sq = 1162\n",
      "cs = 1050\n",
      "el = 745\n",
      "bg = 625\n",
      "uk = 606\n",
      "ar = 587\n",
      "mk = 422\n",
      "th = 420\n",
      "lv = 356\n",
      "zh-cn = 239\n",
      "he = 118\n",
      "fa = 112\n",
      "zh-tw = 70\n",
      "ur = 20\n",
      "bn = 13\n",
      "ml = 11\n",
      "ta = 10\n",
      "mr = 5\n",
      "hi = 4\n",
      "kn = 3\n",
      "pa = 2\n",
      "ne = 1\n"
     ]
    }
   ],
   "source": [
    "input_dir  = r\"comments\\per_video\"\n",
    "output_dir = r\"comments\\preprocessed_comments\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "textOriginal_missing = 0\n",
    "opening_error = 0\n",
    "processed_files = 0\n",
    "\n",
    "language_counter = Counter()\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "total_files = len(csv_files)\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, filename in enumerate(sorted(csv_files)):\n",
    "    if (idx + 1) % 1000 == 0 and total_files > 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        est_total = (elapsed * total_files) / (idx + 1)\n",
    "        est_remaining = max(est_total - elapsed, 0.0)\n",
    "        print(f\"Processed {idx + 1}/{total_files} files in {elapsed:.2f}s.\")\n",
    "        print(f\"Estimated total: {est_total:.2f}s. Remaining: {est_remaining:.2f}s.\")\n",
    "\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "    try:\n",
    "        df_video = pd.read_csv(\n",
    "            file_path,\n",
    "            dtype=str,\n",
    "            on_bad_lines=\"skip\",\n",
    "            low_memory=False,\n",
    "            encoding=\"utf-8\",\n",
    "            encoding_errors=\"ignore\",\n",
    "        )\n",
    "\n",
    "        if \"textOriginal\" in df_video.columns:\n",
    "            texts = df_video[\"textOriginal\"].fillna(\"\")\n",
    "\n",
    "            langs = [safe_detect_lang(x) for x in texts]\n",
    "            df_video[\"lang\"] = langs\n",
    "            language_counter.update(langs)\n",
    "            \n",
    "            df_video[\"preprocessed_comment\"] = [\n",
    "                preprocess_combined(x) if isinstance(x, str) and x != \"\" else np.nan\n",
    "                for x in texts\n",
    "            ]\n",
    "            if idx % 3000 == 0:\n",
    "                print(df_video[\"preprocessed_comment\"])\n",
    "        else:\n",
    "            textOriginal_missing += 1\n",
    "\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        outname = f\"{base}_preprocessed.csv\"\n",
    "        outpath = os.path.join(output_dir, outname)\n",
    "        df_video.to_csv(outpath, index=False, encoding=\"utf-8\")\n",
    "        processed_files += 1\n",
    "\n",
    "    except Exception:\n",
    "        opening_error += 1\n",
    "\n",
    "print(\"\\nProcessing Summary:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"CSV files found: {total_files}\")\n",
    "print(f\"Files successfully processed: {processed_files}\")\n",
    "print(f\"Files with missing 'textOriginal' column: {textOriginal_missing}\")\n",
    "print(f\"File opening errors: {opening_error}\")\n",
    "\n",
    "print(\"\\nLanguage distribution across all comments:\")\n",
    "print(\"-----------------------------------------\")\n",
    "for code, count in language_counter.most_common():\n",
    "    print(f\"{code} = {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bachelor_thesis)",
   "language": "python",
   "name": "bachelor_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
